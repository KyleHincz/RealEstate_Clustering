{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9293475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "\n",
    "import matplotlib.pyplot as plt # For plots\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import datetime\n",
    "import re\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def column_summary(col,dataframe):\n",
    "    # column summary - pass col name as string + dataframe. Receive sorted occurence count and %\n",
    "    # TODO nan handling - atm not showing\n",
    "    pd.set_option('display.max_rows', None)\n",
    "\n",
    "    counts = dataframe[col].value_counts()\n",
    "    percs = dataframe[col].value_counts(normalize=True).mul(100).round(3).astype(str) + '%'\n",
    "    return pd.concat([counts,percs], axis=1, keys=['count', 'percentage'])\n",
    "\n",
    "\n",
    "def analyse_column_list(col_lst, df,show=True):\n",
    "    if show == False:\n",
    "        return None\n",
    "    else:\n",
    "        col_lst1 = column_name_adjuster(col_lst, df)\n",
    "        for column in col_lst1:\n",
    "            print(\"\\n*********\",'\\033[1m' + column + '\\033[0m')\n",
    "            display(column_summary(column,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00789139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_appr_full = pd.read_pickle(\"./IN_dfs/df_appr_full_raw.pkl\")\n",
    "df_comp_full = pd.read_pickle(\"./IN_dfs/df_comp_full_raw.pkl\")\n",
    "print(\"Appriasal Shape\", df_appr_full.shape)\n",
    "print(\"Comp Shape\", df_comp_full.shape)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a628310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669ca9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_columns = [ 'DESIGNSTYLE_SUBJ', 'HEATINGCOOLING_SUBJ', 'ENERGYEFF_SUBJ',\n",
    "       'GARAGECARPORT_SUBJ', 'PORCHPATIODECK_SUBJ' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc0712",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 1000)\n",
    "col = pd.concat([df_appr_full[ 'DESIGNSTYLE_SUBJ'],df_comp_full[ 'DESIGNSTYLE']])\n",
    "col=col.str.lower()\n",
    "df_temp=pd.DataFrame()\n",
    "df_temp[\"DESIGN_STYLE_ORIG\"] = col.copy()\n",
    "df_temp[\"no_comma\"] = df_temp[\"DESIGN_STYLE_ORIG\"].str.replace(',', '.')\n",
    "df_temp[\"no_comma\"] = df_temp[\"DESIGN_STYLE_ORIG\"].str.replace(' ', '.')\n",
    "df_temp['extracted_Number'] = df_temp['no_comma'].str.replace('([A-Za-z]+)', '',regex=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d8ee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nostory = df_temp[~df_temp['extracted_Number'].str.contains(r'\\d+')]# 976083 c+a records with no story number - remove\n",
    "column_summary(\"DESIGN_STYLE_ORIG\",df_nostory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90606963",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_summary(\"DESIGN_STYLE_ORIG\",df_nostory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5706cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#clean up the extracted_number field\n",
    "\n",
    "lst = df_temp['extracted_Number'].unique()\n",
    "#print(len(lst))\n",
    "import re\n",
    "lst_num = []\n",
    "for no in lst:\n",
    "    #print(lst)\n",
    "    #print (no)\n",
    "    try:\n",
    "        test = float(no)\n",
    "        lst_num.append(test)\n",
    "    except Exception as e: \n",
    "        #print(no)\n",
    "        #x = no.lstrip()\n",
    "        x = no.lstrip('0')\n",
    "        #print(x)\n",
    "        temp_list = re.findall(r'[+-]?([1-9]\\d*(\\.\\d*[1-9])?|0\\.\\d*[1-9]+)|\\d+(\\.\\d*[1-9])?', x)#look for numbers\n",
    "        if len(temp_list)==0:\n",
    "            lst_num.append(np.nan)\n",
    "        else:\n",
    "            #print(temp_list)\n",
    "            try:\n",
    "                lst_num.append(float(temp_list[0][0]))#take first number\n",
    "            except Exception as e: \n",
    "                try: \n",
    "                    a = temp_list[0][0]\n",
    "                    a = a.replace('.', '')\n",
    "                    a = a.replace(',', '')\n",
    "                    lst_num.append(float(a))#take second number\n",
    "                except Exception as ee:\n",
    "                    lst_num.append(np.nan)\n",
    "\n",
    "site_dict = dict(zip(lst, lst_num))\n",
    "\n",
    "df_temp[\"Number_of_stories_no_imputation\"] = df_temp[\"extracted_Number\"].map(site_dict.get) #QUICKEST!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2fc3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp[\"Number_of_stories_no_imputation\"] = abs(df_temp[\"Number_of_stories_no_imputation\"])\n",
    "\n",
    "df_temp['Number_of_stories_no_imputation_divided'] = np.round(np.where(df_temp['Number_of_stories_no_imputation'] >=10, \n",
    "                                                                  df_temp['Number_of_stories_no_imputation']/10,\n",
    "                                                                       df_temp['Number_of_stories_no_imputation']), 1)\n",
    "df_temp['Number_of_stories_no_imputation_divided'] = np.round(np.where(df_temp['Number_of_stories_no_imputation_divided'] >=10, \n",
    "                                                                  df_temp['Number_of_stories_no_imputation_divided']/10,\n",
    "                                                                       df_temp['Number_of_stories_no_imputation_divided']), 1)\n",
    "\n",
    "df_temp['Number_of_stories_no_imputation_divided'] = np.round(np.where(df_temp['Number_of_stories_no_imputation_divided'] >=6, \n",
    "                                                                  np.nan,\n",
    "                                                                       df_temp['Number_of_stories_no_imputation_divided']), 1)\n",
    "\n",
    "\n",
    "dict_fix_floors = {0.4:2, 0.8:np.nan, 5.2: np.nan, 0.0: np.nan, 0.1:1.0, 0.2:2.0, 0.3:3, 0.7:np.nan,}\n",
    "\n",
    "df_temp[\"Number_of_stories_no_imputation_divided\"] = df_temp[\"Number_of_stories_no_imputation_divided\"].replace(dict_fix_floors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3367e3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_summary(\"Number_of_stories_no_imputation_divided\",df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216e3ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.drop(columns = [\"no_comma\",\"extracted_Number\",\"Number_of_stories_no_imputation\"])\n",
    "df_temp = df_temp.rename(columns={'Number_of_stories_no_imputation_divided': 'Number_of_stories_no_imputation'})\n",
    "print(df_temp[df_temp[\"Number_of_stories_no_imputation\"].isnull()].shape)# 976k of rows with no stories\n",
    "df_temp[\"Number_of_stories_impute_to1\"] = df_temp[\"Number_of_stories_no_imputation\"].fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bc65c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Write a function, using simple if... elif syntax \n",
    "def _conditions1(row):    \n",
    "    if row[\"DESIGN_STYLE_ORIG\"].startswith(\"dt\"): Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].startswith(\"sd\"): Attachment_type = \"SD\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].startswith(\"at\"): Attachment_type = \"AT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"ranch\")>-1: Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"trad\")>-1: Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"bunga\")>-1: Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"spa\")>-1: Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"col\")>-1: Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"uth\")>-1: Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"sth\")>-1: Attachment_type = \"DT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"end\")>-1: Attachment_type = \"SD\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"town\")>-1: Attachment_type = \"AT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"twn\")>-1: Attachment_type = \"AT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"th\")>-1: Attachment_type = \"AT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"row\")>-1: Attachment_type = \"AT\"\n",
    "    elif row[\"DESIGN_STYLE_ORIG\"].find(\"cond\")>-1: Attachment_type = \"AT\"\n",
    "\n",
    "    else: Attachment_type = \"DT\"\n",
    "        \n",
    "    return Attachment_type\n",
    "# Create a new column based on the function\n",
    "df_temp[\"Attachment_type\"] = df_temp.apply(_conditions1, axis=1)\n",
    "df_temp.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea332bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.concat([df_temp, pd.get_dummies(df_temp[\"Attachment_type\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fee111",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df_temp['DS_Bungalow'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"1story\",\"1sty\",\"1 level\",\"one\",\"sngl\",\"1-story\",\"1.5\",\"single-level\",\"one-story\",\"bung\",\"bgl\",\"bng\",\"1 story\",\n",
    "                                                                                       \"single level\",\"one story\",\"singlelvl\",\"single lvl\"])), 1, 0)\n",
    "df_temp['DS_Cabin'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"cabin\",\"log\",\"chalet\",\"alpine\"])), 1, 0)\n",
    "df_temp['DS_Classical'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"clas\"])), 1, 0)\n",
    "df_temp['DS_Colonial'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"colon\",\"a-col\",\"col\"])), 1, 0)\n",
    "df_temp['DS_Cottage'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"cott\"])), 1, 0)\n",
    "df_temp['DS_Contemp'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"temp\",\"cont\", \"ctmp\",\"modern\",\"cntm\",\"custom\",\"cntp\",\"ctmpr\"])), 1, 0)\n",
    "df_temp['DS_Conventional'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"conv\"])), 1, 0)\n",
    "df_temp['DS_CapeCod'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"cape\", \"cod\"])), 1, 0)\n",
    "df_temp['DS_Craftsman'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"craft\",\"crf\"])), 1, 0)\n",
    "df_temp['DS_Duplex'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"dupl\"])), 1, 0)\n",
    "df_temp['DS_English'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"engl\",\"regency\",\"queen\",\"anne\"])), 1, 0)\n",
    "df_temp['DS_French'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"french\"])), 1, 0)\n",
    "df_temp['DS_Georgian'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"georg\",\"geor\",\"grg\"])), 1, 0)\n",
    "df_temp['DS_Medit'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"med\",\"mdtrn\",\"mdrn\"])), 1, 0)\n",
    "df_temp['DS_MidCentury'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"mid-\",\"century\",\"mid \",\"midc\"])), 1, 0)\n",
    "df_temp['DS_Mountain'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"mtn\",\"mount\",\"mdrn\"])), 1, 0)\n",
    "df_temp['DS_NeoEclect'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"ecl\",\"neoe\",\"neoclctc\",\"neo e\"])), 1, 0)\n",
    "df_temp['DS_NewAmerican'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"amer\",\"newame\",\"amcn\",\"new am\",\"newam\"])), 1, 0)\n",
    "df_temp['DS_Patio'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"patio\",\"tract\"])), 1, 0)\n",
    "df_temp['DS_Ranch'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"ranch\",\"rnch\",\"rnh\",\"farm\",\"rch\",\"calif\",\"rh\",\"frm\"])), 1, 0)\n",
    "df_temp['DS_Rambler'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"ramb\",\"rmblr\"])), 1, 0)\n",
    "df_temp['DS_SantaBarb'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"barb\",\"brb\"])), 1, 0)\n",
    "df_temp['DS_Spanish'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"span\",\"villa\",\"santa fe\",\"fe\",\"spn\",\"spain\"])), 1, 0)\n",
    "df_temp['DS_SplitLevel'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"split\",\"multi\",\"bi-level\"])), 1, 0)\n",
    "df_temp['DS_SWest'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"south\", \"sth\", \"sw\", \"west\",\"wst\"])), 1, 0)\n",
    "df_temp['DS_Territorial'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"terri\"])), 1, 0)\n",
    "\n",
    "df_temp['DS_Townhouse'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"wth\",\"twh\",\"t-house\",\"tnh\",\n",
    "                        \"row\",\"twn\",\"town\",\"thouse\",\"twnh\",\n",
    "                        \"thse\",\"rowth\",\"rowhouse\",\n",
    "                    \"th/int\",\"intth\",\"midth\",\"endth\",\"th/\",\"/th\",\"t/h\",\";th\",\"-th\"])), 1, 0) #,\"th/\",\"/th\"\n",
    "\n",
    "df_temp['DS_Trad'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"trad\",\"trd\"])), 1, 0)\n",
    "df_temp['DS_Tudor'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"tudo\"])), 1, 0)\n",
    "df_temp['DS_Tuscan'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"tusc\",\"ital\"])), 1, 0)\n",
    "df_temp['DS_TwoStory'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"sq\",\"square\",\"2sty\",\"2 sty\",\"2story\",\"splt\",\"bilevel\",\"two\",\"2 story\",\"2-story\", \"two story\", \"bi level\",\"splt lvl\",\"tri-level\"])), 1, 0)\n",
    "df_temp['DS_Victorian'] = np.where(df_temp['DESIGN_STYLE_ORIG'].str.contains(\"|\".join([\"vict\"])), 1, 0)\n",
    "df_temp['_DS_SUM'] = df_temp[[col for col in df_temp.columns if col.startswith('DS_')]].sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aefcf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = df_temp.drop(columns = [\"Attachment_type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1697d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp.to_pickle(\"./OUT_dfs/df_temp.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e870de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print Deliberate stop here to avoid memory error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bc869c",
   "metadata": {},
   "source": [
    "# Load appraisal dataframe to do the merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ada340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc8e3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_pickle(\"./OUT_dfs/df_temp.pkl\")\n",
    "df_appr_nona = pd.read_pickle(\"./OUT_dfs/df_appr_full_processed_nona_no_outliers.pkl\")\n",
    "df_appr_full = pd.read_pickle(\"./IN_dfs/df_appr_full_raw.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a3030a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply radians to long and lat for later use\n",
    "df_appr_nona[['APPRLATITUDE', 'APPRLONGITUDE']]=df_appr_nona[['APPRLATITUDE', 'APPRLONGITUDE']].apply(np.radians,axis=0)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec2e6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = df_appr_nona.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4230abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns in full appr dataframe to get ready for merge\n",
    "new_names = {'DESIGNSTYLE_SUBJ':'DESIGNSTYLE', 'HEATINGCOOLING_SUBJ':'HEATINGCOOLING', 'ENERGYEFF_SUBJ':'ENERGYEFF', \n",
    "             'GARAGECARPORT_SUBJ':'GARAGECARPORT',\"PORCHPATIODECK_SUBJ\":\"PORCHPATIODECK\"}\n",
    "df_appr_full = df_appr_full.rename(index=str, columns=new_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ead91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_appr_full[['DESIGNSTYLE', 'HEATINGCOOLING', 'ENERGYEFF',\n",
    "       'GARAGECARPORT', 'PORCHPATIODECK' ]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7df127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge df_a and df_c with full ones to bring back the above 4 features\n",
    "\n",
    "df_a_new = pd.merge(df_a,df_appr_full[['SUBJ_APPR_ID','DESIGNSTYLE', 'HEATINGCOOLING', 'ENERGYEFF',\n",
    "       'GARAGECARPORT', 'PORCHPATIODECK' ]], how=\"left\",left_on='SUBJ_APPR_ID', right_on='SUBJ_APPR_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d299a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_new.to_pickle(\"./OUT_dfs/df_a_new_ignore.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print Deliberate stop here to avoid memory error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b758a8",
   "metadata": {},
   "source": [
    "# next merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea15ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c25955f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_a_new = pd.read_pickle(\"./OUT_dfs/df_a_new_ignore.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e03bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_a_new[\"DESIGNSTYLE\"]=df_a_new[\"DESIGNSTYLE\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c6ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_temp[\"DESIGNSTYLE\"].dtypes\n",
    "df_a_new[\"DESIGNSTYLE\"].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2663530b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pd.read_pickle(\"./OUT_dfs/df_temp.pkl\")\n",
    "df_temp.rename(columns={'DESIGN_STYLE_ORIG':'DESIGNSTYLE'}, inplace=True)\n",
    "df_temp[\"DESIGNSTYLE\"]=df_temp[\"DESIGNSTYLE\"].astype(str)\n",
    "dict1 = df_temp.set_index(\"DESIGNSTYLE\").apply(list, 1).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d59df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "df_a_newzzzz = df_a_new.copy()\n",
    "df_a_newzzzz[\"DSTEST\"] = df_a_new[\"DESIGNSTYLE\"].str.lower().map(dict1.get)\n",
    "df_a_newzzzz[df_temp.columns[1:]] = pd.DataFrame(df_a_newzzzz.DSTEST.tolist(), index= df_a_newzzzz.index)\n",
    "\n",
    "df_a_newzzzz = df_a_newzzzz.drop(columns = [\"DSTEST\"])\n",
    "#df_a_newzzzz.tail(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc70c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_newzzzz.to_pickle(\"./OUT_dfs/df_a1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6cc700",
   "metadata": {},
   "source": [
    "# Load Comp dataframe to merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37048e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e150d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp_full = pd.read_pickle(\"./IN_dfs/df_comp_full_raw.pkl\")\n",
    "uniqueComps = pd.read_pickle(\"./OUT_dfs/uniqueComps.pkl\")\n",
    "uniqueComps[['APPRLATITUDE', 'APPRLONGITUDE']]=uniqueComps[['APPRLATITUDE', 'APPRLONGITUDE']].apply(np.radians,axis=0)\n",
    "df_c = uniqueComps.copy()\n",
    "#df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bac8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_new = pd.merge(df_c,df_comp_full[['SUBJ_APPR_ID',\"COMPNUM\",'DESIGNSTYLE', 'HEATINGCOOLING', 'ENERGYEFF',\n",
    "       'GARAGECARPORT', 'PORCHPATIODECK' ]], how=\"left\",left_on=['SUBJ_APPR_ID',\"COMPNUM\"], right_on=['SUBJ_APPR_ID',\"COMPNUM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eba16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c_new[\"DESIGNSTYLE\"]=df_c_new[\"DESIGNSTYLE\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab24065",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "df_a_newzzzz = df_c_new.copy()\n",
    "df_a_newzzzz[\"DSTEST\"] = df_c_new[\"DESIGNSTYLE\"].str.lower().map(dict1.get)\n",
    "df_a_newzzzz[df_temp.columns[1:]] = pd.DataFrame(df_a_newzzzz.DSTEST.tolist(), index= df_a_newzzzz.index)\n",
    "\n",
    "df_a_newzzzz = df_a_newzzzz.drop(columns = [\"DSTEST\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a_newzzzz.to_pickle(\"./OUT_dfs/df_c1.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
