{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439f450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from math import sqrt, cos, sin, asin, radians\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fa31d9",
   "metadata": {},
   "source": [
    "# Import the processed data pickles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a6a926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appr = pd.read_pickle(\"./OUT_dfs/df_appr_full_processed.pkl\")\n",
    "# comp = pd.read_pickle(\"./OUT_dfs/df_comp_full_processed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464db83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the datasets:\n",
    "df_appr_nona = pd.read_pickle(\"./OUT_dfs/df_appr_full_processed_nona.pkl\")\n",
    "df_comp_unique = pd.read_pickle(\"./OUT_dfs/uniqueComps.pkl\")\n",
    "\n",
    "# Dictionary of appraisal\n",
    "dict_apprid_to_uniquecompidnew = pickle.load(open(\"./OUT_dfs/dict_apprid_to_uniquecompidnew\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55ece56",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_appr = 856775\n",
    "dict_apprid_to_uniquecompidnew[test_appr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb984fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of loadings:\n",
    "appr = df_appr_nona.copy()\n",
    "comp = df_comp_unique.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3c8a92",
   "metadata": {},
   "source": [
    "# Drop rows that have null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to drop any NaN in the defined columns:\n",
    "\n",
    "def remove_nan(a_df, c_df):\n",
    "    a_cols = ['APPRLONGITUDE', 'APPRLATITUDE', 'SALEDATE']\n",
    "    c_cols = ['APPRLONGITUDE', 'APPRLATITUDE', 'SALEDATE'] # COMPSALEDATE\n",
    "    a_full = a_df.dropna(subset=a_cols)\n",
    "    c_full = c_df.dropna(subset=c_cols)\n",
    "    \n",
    "    return a_full, c_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599bcb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "appr_no_nan, comp_no_nan = remove_nan(appr, comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d3a387",
   "metadata": {},
   "source": [
    "# Dataset for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47697592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_or_sample_dataset(a_df, c_df, sub_sample=None, state=None):\n",
    "    if sub_sample == None and state == None:\n",
    "        a_train = a_df.copy() # computationally expensive\n",
    "        print('Full dataset loaded successfully!')\n",
    "    elif sub_sample == None and state!=None:\n",
    "        a_train = a_df[a_df['STATE'] == county]\n",
    "        print('Subset from state ' + state + ' loaded successfully!')\n",
    "    elif sub_sample != None and state == None:\n",
    "        a_train = a_df.sample(n=sub_sample)\n",
    "        print('Subset of n = ' + str(sub_sample) + ' loaded successfully!')\n",
    "    else:\n",
    "        a_temp =  a_df[a_df['STATE']==state]\n",
    "        a_train = a_temp.sample(n=sub_sample)\n",
    "        print('Subset of state' + state + ' with n = ' + str(sub_sample) +' loaded successfully!')\n",
    "    \n",
    "    c_train = pd.DataFrame()\n",
    "    for appr_id in a_train['SUBJ_APPR_ID']:\n",
    "        comp_df_temp = c_df[c_df['UNIQUECOMPIDNEW'].isin(dict_apprid_to_uniquecompidnew[appr_id])]\n",
    "        c_train = pd.concat([c_train, comp_df_temp])\n",
    "    \n",
    "#     c_train_sample = c_df.sample(n=2000) # choose how many extra comparables to include\n",
    "#     c_train = pd.concat([c_train, c_train_sample])\n",
    "    c_train.drop_duplicates(subset=['UNIQUECOMPIDNEW'],keep='first', inplace=True)\n",
    "    \n",
    "    print('Full comparables dataset loaded successfully!')\n",
    "    print('')\n",
    "    print('Number of rows in appraisals dataset: ', a_train.shape[0])\n",
    "    print('Number of rows in unique comparables dataset: ', c_train.shape[0])\n",
    "    \n",
    "    return a_train, c_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb922e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "appr_df, comp_df  = full_or_sample_dataset(appr_no_nan, comp_no_nan, sub_sample=10000, state=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71fecc8",
   "metadata": {},
   "source": [
    "# **MODELS FOR FEATURE IMPORTANCE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5104cf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns categorization:\n",
    "appr_excl_cols = ['SUBJ_APPR_ID', 'COMPNUM', \n",
    "                  'ADDRESS1', 'CITY', 'STATE', 'ZIPCODE', 'COUNTY', 'COMPSALEDATE']\n",
    "\n",
    "comp_excl_cols = ['SUBJ_APPR_ID', 'COMPNUM', 'UNIQUECOMPIDNEW', \n",
    "                  'ADDRESS1', 'CITY', 'STATE', 'ZIPCODE', 'COUNTY', 'COMPSALEDATE']\n",
    "\n",
    "calc_cols = ['APPRLATITUDE', 'APPRLONGITUDE', 'SALEDATE']\n",
    "\n",
    "categorical_cols = ['LOCRTGNEUTRAL', 'LOCRTGBENEFICIAL', 'LOCRTGADVERSE', 'LOCRESIDENTIAL', \n",
    "                    'LOCINDUSTRIAL', 'LOCCOMMERCIAL', 'LOCBUSYROAD', 'LOCWATERFRONT', 'LOCGOLFCOURSE', \n",
    "                    'LOCADJPARK', 'LOCADJPOWERLINE', 'LOCLANDFILL', 'LOCPUBLICTRAN', \n",
    "                    'VIEWRTGNEUTRAL', 'VIEWRTGBENEFICIAL', 'VIEWRTGADVERSE', 'VIEWTYPEWATER', \n",
    "                    'VIEWTYPEPASTORAL', 'VIEWTYPEWOOD', 'VIEWTYPEPARK', 'VIEWTYPEGOLFCOURSE', \n",
    "                    'VIEWTYPECITYSKYLINE', 'VIEWTYPEMOUNTAIN', 'VIEWTYPERESIDENTIAL', 'VIEWTYPECITYSTREET', \n",
    "                    'VIEWTYPEINDUSTRIAL', 'VIEWTYPEPOWERLINE', 'VIEWTYPELIMITED', \n",
    "                    'QUALITYOFCONSTQ1', 'QUALITYOFCONSTQ2', 'QUALITYOFCONSTQ3', 'QUALITYOFCONSTQ4', \n",
    "                    'QUALITYOFCONSTQ5', 'QUALITYOFCONSTQ6', \n",
    "                    'CONDITIONC1', 'CONDITIONC2', 'CONDITIONC3', 'CONDITIONC4', 'CONDITIONC5', 'CONDITIONC6']\n",
    "\n",
    "numerical_cols = ['TOTALRM', 'BDRM', 'BLGRDTOTALSQFT', 'BLGRDFINISHSQFT', 'BLGRDRECRM', \n",
    "                  'BLGRDBEDRM', 'BLGRDOTHERRM', 'GROSSLIVINGAREA', 'ACTUALAGE', 'FULL_BATH', \n",
    "                  'FULL_BLGRDBATHRM', 'HALF_BATH', 'HALF_BLGRDBATHRM', 'SITEAREASQFT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249e94a7",
   "metadata": {},
   "source": [
    "## *Scale data:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5db1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ad35a0",
   "metadata": {},
   "source": [
    "## *Principal Component Analysis:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d84d8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.concat([appr_df, comp_df], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89b6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scaled = full_df.copy()\n",
    "full_scaled[['TOTALRM', 'BDRM', 'BLGRDTOTALSQFT', 'BLGRDFINISHSQFT', 'BLGRDRECRM', 'BLGRDBEDRM', 'BLGRDOTHERRM', \n",
    "             'GROSSLIVINGAREA', 'ACTUALAGE', 'FULL_BATH', 'FULL_BLGRDBATHRM', 'HALF_BATH', 'HALF_BLGRDBATHRM', \n",
    "             'SITEAREASQFT']] = scaler.fit_transform(full_scaled[['TOTALRM', 'BDRM', 'BLGRDTOTALSQFT', 'BLGRDFINISHSQFT', \n",
    "                                                                  'BLGRDRECRM', 'BLGRDBEDRM', 'BLGRDOTHERRM', \n",
    "                                                                  'GROSSLIVINGAREA', 'ACTUALAGE', 'FULL_BATH', \n",
    "                                                                  'FULL_BLGRDBATHRM', 'HALF_BATH', 'HALF_BLGRDBATHRM', \n",
    "                                                                  'SITEAREASQFT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd3bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed08e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scaled.drop(['SUBJ_APPR_ID', 'COMPNUM','ADDRESS1', 'CITY', 'STATE', 'ZIPCODE', 'COUNTY', 'COMPSALEDATE',\n",
    "                  'APPRLATITUDE', 'APPRLONGITUDE', 'COMPSALEDATE'], \n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd31b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scaled.drop(['SALEDATE', 'UNIQUECOMPIDNEW'], \n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d52e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_scaled.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA().fit(full_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef9157",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pca.explained_variance_ratio_.cumsum(), lw=2, color='darkgreen')\n",
    "plt.title('Cumulative explained variance by number of principal components', size=10)\n",
    "plt.xticks(range(0, 55), size=5, rotation='vertical')\n",
    "plt.axvline(10, 0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511b09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_not_scaled = full_df.copy()\n",
    "full_not_scaled.drop(['SUBJ_APPR_ID', 'COMPNUM','ADDRESS1', 'CITY', 'STATE', 'ZIPCODE', 'COUNTY', 'COMPSALEDATE',\n",
    "                      'APPRLATITUDE', 'APPRLONGITUDE', 'SALEDATE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d159cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_not_scaled.drop(['UNIQUECOMPIDNEW'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e60eede",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_loadings = pd.DataFrame(\n",
    "    data=pca.components_.T * np.sqrt(pca.explained_variance_), \n",
    "    columns=[f'PC{i}' for i in range(1, len(full_not_scaled.columns) + 1)],\n",
    "    index=full_not_scaled.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58ce00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_loadings = pca_loadings.sort_values(by='PC1', ascending=False)[['PC1']]\n",
    "pc1_loadings = pc1_loadings.reset_index()\n",
    "pc1_loadings.columns = ['Attribute', 'CorrWithPC1']\n",
    "\n",
    "plt.bar(x=pc1_loadings['Attribute'], height=pc1_loadings['CorrWithPC1'], color='green')\n",
    "plt.title('PCA loading scores (first principal component)', size=10)\n",
    "plt.xticks(rotation='vertical', size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c89e63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2_loadings = pca_loadings.sort_values(by='PC2', ascending=False)[['PC2']]\n",
    "pc2_loadings = pc2_loadings.reset_index()\n",
    "pc2_loadings.columns = ['Attribute', 'CorrWithPC2']\n",
    "\n",
    "plt.bar(x=pc2_loadings['Attribute'], height=pc2_loadings['CorrWithPC2'], color='green')\n",
    "plt.title('PCA loading scores (second principal component)', size=10)\n",
    "plt.xticks(rotation='vertical', size=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaec81ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take top 10 principal components that explain approx. 90% of the variance in the dataset:\n",
    "pc_df_list = []\n",
    "for i in range(10):\n",
    "    pc = 'PC'+str(i+1)\n",
    "    corr = 'CorrWithPC'+str(i+1)\n",
    "    pc_i_loadings = pca_loadings.sort_values(by=pc, ascending=False)[[pc]]\n",
    "    pc_i_loadings.columns = [corr]\n",
    "    pc_df_list.append(pc_i_loadings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043601bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df = pd.concat(pc_df_list, axis=\"columns\")\n",
    "pc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95baafd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert correlations into absolute values (does not matter if positive or negative)\n",
    "pc_df = pc_df.abs()\n",
    "pc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d596e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_df = pc_df.drop(['TotalCorrelation'], axis=1, errors='ignore') # in case it already exists, drop\n",
    "pc_df[\"TotalCorrelation\"] = pc_df.sum(axis=1)\n",
    "pc_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ee8a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pc_df = pc_df.sort_values(by=['TotalCorrelation'], ascending=False)\n",
    "final_pc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1ee764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 features:\n",
    "n_var = 20\n",
    "result = final_pc_df['TotalCorrelation'][:n_var]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11fd6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_features = list(result.index)\n",
    "# pca_features.append('APPRLONGITUDE')\n",
    "# pca_features.append('APPRLATITUDE')\n",
    "# pca_features.append('SALEDATE')\n",
    "# pca_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec356e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create copies of loadings:\n",
    "# pca_feat_appr = df_appr_nona.copy()\n",
    "# pca_feat_appr = pca_feat_appr[pca_features]\n",
    "# pca_feat_comp = df_comp_unique.copy()\n",
    "# pca_feat_comp = pca_feat_comp[pca_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9b2543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_feat_appr.to_pickle(\"./OUT_dfs/pca_feat_appr.pkl\")\n",
    "# pca_feat_comp.to_pickle(\"./OUT_dfs/pca_feat_comp.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
